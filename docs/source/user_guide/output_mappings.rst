:github_url: https://github.com/merlinquantum/merlin

=========================
Output Measurement Guide
=========================

Merlin now exposes quantum-to-classical conversion through two orthogonal concepts:

- :class:`~merlin.measurement.strategies.MeasurementStrategy` selects how results are extracted from the quantum simulation or hardware backend.
- :class:`~merlin.utils.grouping.mappers.LexGrouping` and :class:`~merlin.utils.grouping.mappers.ModGrouping` provide optional post-processing of outputs.

The legacy output mapping strategy enum has been removed. This page explains how to build measurement pipelines with the new API.

Measurement Strategies
======================

PROBABILITIES
-----------------------

Produces the probability of observing each Fock state. If the simulation returns amplitudes, Merlin turns them into probabilities via :math:`|a|^2`.

.. code-block:: python

    builder = CircuitBuilder(n_modes=5)
    # Add whatever to your builder

    quantum_layer = QuantumLayer(.
        input_size=4,
        builder=builder,
        n_photons=2,
        measurement_strategy=MeasurementStrategy.PROBABILITIES,  # Optional because this is its default value
    )

The underlying PyTorch module is :class:`~merlin.measurement.mappers.Probabilities`.
Characteristics:

- Output shape matches the number of Fock states generated by the experiment.
- Values are real, non-negative, and sum to one.
- Ideal when classical code consumes the raw quantum probability distribution.

Extensions:

- Add ``torch.nn.Linear`` or any classical layer after the quantum layer to map the probabilities to logits/regression targets.
- Combine with :class:`~merlin.utils.grouping.mappers.LexGrouping` or :class:`~merlin.utils.grouping.mappers.ModGrouping` when you need fewer output features and don't want to increase the number of parameters.

MODE_EXPECTATIONS
----------------

Marginalises the Fock distribution to per-mode expectation values.

.. code-block:: python

    builder = CircuitBuilder(n_modes=5)
    # Add whatever to your builder

    quantum_layer = QuantumLayer(.
        input_size=4,
        builder=builder,
        n_photons=2,
        measurement_strategy=MeasurementStrategy.MODE_EXPECTATIONS,
    )

Use :class:`~merlin.measurement.mappers.ModeExpectations` when working directly with the mapper.
Key properties:

- ``no_bunching=True`` (default) reports occupancy probabilities per mode.
- ``no_bunching=False`` returns the expected photon count per mode.
- Output size always equals the number of modes.

AMPLITUDES
---------------

Returns the complex amplitudes directly. This strategy is only meaningful in simulation, because amplitudes cannot be measured or obtained on hardware.

.. code-block:: python

    builder = CircuitBuilder(n_modes=5)
    # Add whatever to your builder

    quantum_layer = QuantumLayer(.
        input_size=4,
        builder=builder,
        n_photons=2,
        measurement_strategy=MeasurementStrategy.AMPLITUDES,
    )

Use this strategy for debugging, algorithmic research, or when a classical routine manipulates complex amplitudes directly. The output is a complex tensor normalised to unit norm (within numerical precision).

The helper module is :class:`~merlin.measurement.mappers.Amplitudes`.

Grouping Modules
================

Grouping modules reshape the output of :class:`~merlin.measurement.strategies.MeasurementStrategy.PROBABILITIES` into smaller feature sets while preserving differentiability.

LexGrouping
-----------

Groups consecutive values into equally sized buckets. Padding with zeros ensures all buckets have the same width.

.. code-block:: python

    grouped = nn.Sequential(
        quantum_layer,
        ML.LexGrouping(input_size=quantum_layer.output_size, output_size=8),
    )

Useful when the order of Fock states carries meaning (e.g., lexicographic encoding). The module preserves probability mass and supports batched inputs.

Example (single vector)::

    >>> p = torch.tensor([0.1, 0.2, 0.4, 0.3])
    >>> mapper = ML.LexGrouping(input_size=4, output_size=2)
    >>> mapper(p)
    tensor([0.3000, 0.7000])

ModGrouping
-----------

Sums values sharing the same index modulo ``output_size``. When ``output_size`` exceeds ``input_size``, the layer pads with zeros.

.. code-block:: python

    grouped = nn.Sequential(
        quantum_layer,
        ML.ModGrouping(input_size=quantum_layer.output_size, output_size=8),
    )

This is effective for cyclic structures (e.g., periodic sensors) where indices wrapping around the distribution should be combined.

Example (single vector)::

    >>> p = torch.tensor([0.1, 0.2, 0.3, 0.4])
    >>> mapper = ML.ModGrouping(input_size=4, output_size=2)
    >>> mapper(p)
    tensor([0.4000, 0.6000])

Chaining Measurement and Grouping
---------------------------------

.. code-block:: python

    import torch.nn as nn

    builder = CircuitBuilder(n_modes=4)
    # Add whatever to your builder

    quantum_layer = QuantumLayer(.
        input_size=2,
        builder=builder,
        n_photons=2,
        measurement_strategy=MeasurementStrategy.PROBABILITIES,
    )

    quantum_pipeline = nn.Sequential(
        quantum_layer,
        ML.ModGrouping(input_size=quantum_layer.output_size, output_size=3),
        nn.Linear(3, 1),
    )

Migrating from OutputMappingStrategy
====================================

Legacy name → new pipeline:

- ``OutputMappingStrategy.NONE`` → ``MeasurementStrategy.PROBABILITIES``
- ``OutputMappingStrategy.LINEAR`` → ``MeasurementStrategy.PROBABILITIES`` followed by a torch.nn.Linear layer
- ``OutputMappingStrategy.LEXGROUPING`` or ``GROUPING`` → ``MeasurementStrategy.PROBABILITIES`` + :class:`~merlin.utils.grouping.mappers.LexGrouping`
- ``OutputMappingStrategy.MODGROUPING`` → ``MeasurementStrategy.PROBABILITIES`` + :class:`~merlin.utils.grouping.mappers.ModGrouping`

Selection Cheat Sheet
=====================

.. list-table::
   :header-rows: 1
   :widths: 25 35 40

   * - Scenario
     - Recommended Pipeline
     - Notes
   * - Classification / Regression
     - ``PROBABILITIES`` + classical head
     - Obtain logits or arbitrary ranges with ``nn.Linear`` or deeper networks.
   * - Structured probability outputs
     - ``PROBABILITIES`` + ``LexGrouping`` / ``ModGrouping``
     - Preserves probability mass while reducing dimensionality.
   * - Hardware-friendly analytics
     - ``MODE_EXPECTATIONS`` (``no_bunching`` to taste)
     - Outputs one feature per mode, easy to interpret.
   * - Algorithm debugging
     - ``AMPLITUDES``
     - Complex amplitudes, simulation only.

Validation Tips
===============

- :class:`~merlin.measurement.mappers.Probabilities` automatically detects whether inputs are amplitudes or probabilities by checking the :math:`\ell_2` norm.
- :class:`~merlin.measurement.mappers.ModeExpectations` stores the marginalisation mask as a buffer, so it moves with the model across devices.
- ``LexGrouping`` and ``ModGrouping`` are differentiable and keep gradients flowing back to the quantum layer.
